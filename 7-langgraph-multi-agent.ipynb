{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM Agents with LLama3 and LangGraph\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you will learn how to build and deploy LLM (Large Language Model) agents using LLama3 and LangGraph. These agents will be capable of processing natural language inputs, generating comprehensive plans, and handling complex workflows. By the end of this notebook, you will understand how to:\n",
    "\n",
    "1. Set up and configure a language model using LLama3.\n",
    "2. Define and manage the state for agents in a workflow.\n",
    "3. Implement and customize agent classes for specific tasks.\n",
    "4. Construct and compile a workflow graph using LangGraph.\n",
    "5. Execute the workflow and handle outputs effectively.\n",
    "\n",
    "## Basic Concepts\n",
    "\n",
    "Before diving into the implementation, it's essential to understand some basic concepts:\n",
    "\n",
    "- **LLM (Large Language Model):** A machine learning model trained on vast amounts of text data to understand and generate human-like language. LLama3 is an example of such a model.\n",
    "\n",
    "- **Agent:** A software component that interacts with the LLM to perform specific tasks, such as generating responses or processing information. In this notebook, we implement agents that can handle various aspects of a workflow.\n",
    "\n",
    "- **State:** A shared data structure that stores the context and data required by agents. The state is critical for maintaining continuity and passing information between different parts of the workflow.\n",
    "\n",
    "- **Workflow Graph:** A structured representation of the workflow, where nodes represent agents and edges define the flow of information and control. LangGraph is used to construct and manage these workflow graphs.\n",
    "\n",
    "- **Prompt Engineering:** The process of crafting prompts that guide the LLM's responses. Proper prompt engineering is crucial for ensuring the model generates relevant and accurate outputs.\n",
    "\n",
    "Understanding these concepts will provide a solid foundation as we proceed with the practical implementation of LLM agents and workflows in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "Before we dive into building our agent, we need to set up the necessary environment. This involves installing required packages and ensuring our Python environment is ready for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.1.15)\n",
      "Requirement already satisfied: arxiv in ./.conda/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: wikipedia in ./.conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.22 in ./.conda/lib/python3.11/site-packages (from langgraph) (0.2.23)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in ./.conda/lib/python3.11/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in ./.conda/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.conda/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: sgmllib3k in ./.conda/lib/python3.11/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.conda/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.22->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install termcolor for colored terminal outputs\n",
    "%pip install termcolor langgraph arxiv wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from termcolor import colored\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "In this section, we set up the configuration for the Ollama model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Ollama Model\n",
    "\n",
    "The `setup_ollama_model` function configures the model settings, including the endpoint, model name, system prompt, and other parameters. This setup is essential for initializing the model with the correct configuration, ensuring it can process queries and utilize the tools effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ollama_model(model, temperature=0, stop=None):\n",
    "    \"\"\"\n",
    "    Sets up the Ollama model configuration.\n",
    "\n",
    "    Parameters:\n",
    "    model (str): The name of the model to use.\n",
    "    temperature (float): The temperature setting for the model.\n",
    "    stop (str): The stop token for the model.\n",
    "\n",
    "    Returns:\n",
    "    dict: Configuration for the Ollama model.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"model_endpoint\": \"http://localhost:11434/api/generate\",\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"headers\": {\"Content-Type\": \"application/json\"},\n",
    "        \"stop\": stop,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example configuration\n",
    "ollama_config = setup_ollama_model(model=\"llama3:instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Defining the Agent Graph State\n",
    "\n",
    "In this step, we define the structure of the state that our agents will use to store and communicate information. This state acts as a shared memory that different components of the system can access and modify. We use the `TypedDict` from the `typing` module to define the expected structure and types of data within the state. This helps ensure consistency and correctness when accessing or updating the state, making it easier to manage complex workflows and data dependencies.\n",
    "\n",
    "The `AgentGraphState` class includes fields for the research question, responses from the planner agent, and any final outputs or end states. The `get_agent_graph`_state function is used to retrieve specific parts of the state based on a key, facilitating modular and reusable access to the state data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Define the state object for the agent graph\n",
    "class AgentGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    This class defines the structure of the agent graph state.\n",
    "    \n",
    "    Attributes:\n",
    "    research_question (str): The main research question the agent is working on.\n",
    "    planner_response (list): A list to store responses from the planner agent.\n",
    "    end_chain (list): A list to store the final outputs or end states.\n",
    "    \"\"\"\n",
    "    research_question: str\n",
    "    planner_response: Annotated[list, add_messages]\n",
    "    tools_response: Annotated[list, add_messages]\n",
    "    research_response: Annotated[list, add_messages]\n",
    "    end_chain: Annotated[list, add_messages]\n",
    "\n",
    "# Function to retrieve specific parts of the agent state\n",
    "def get_agent_graph_state(state: AgentGraphState, state_key: str):\n",
    "    \"\"\"\n",
    "    Retrieves specific parts of the agent state based on the provided key.\n",
    "    \n",
    "    Parameters:\n",
    "    state (AgentGraphState): The current state of the agent.\n",
    "    state_key (str): The key indicating which part of the state to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    list or None: The requested state data or None if the key is not recognized.\n",
    "    \"\"\"\n",
    "    if state_key == \"planner_all\":\n",
    "        return state[\"planner_response\"]\n",
    "    elif state_key == \"planner_latest\":\n",
    "        return state[\"planner_response\"][-1] if state[\"planner_response\"] else []\n",
    "\n",
    "    if state_key == \"tools_all\":\n",
    "        return state[\"tools_response\"]\n",
    "    elif state_key == \"tools_latest\":\n",
    "        return state[\"tools_response\"][-1] if state[\"tools_response\"] else []\n",
    "\n",
    "    if state_key == \"research_all\":\n",
    "        return state[\"research_response\"]\n",
    "    elif state_key == \"research_latest\":\n",
    "        return state[\"research_response\"][-1] if state[\"research_response\"] else []\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Initial state setup\n",
    "state = {\n",
    "    \"research_question\": \"\",\n",
    "    \"planner_response\": [],\n",
    "    \"tools_response\": [],\n",
    "    \"research_response\": [],\n",
    "    \"end_chain\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Class Definition\n",
    "\n",
    "In this section, we define the `Agent` class, which serves as a base class for different types of agents in our system. An agent is a component that interacts with the language model to perform specific tasks, such as generating responses or processing information. The `Agent` class manages the configuration and state associated with the language model, allowing for easy setup and reuse of model configurations across different agents.\n",
    "\n",
    "The class includes methods for initializing the agent with a specific model configuration and updating the agent's state. The state encapsulates the context or memory of the agent, enabling it to maintain continuity across interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state: AgentGraphState, model_config: dict):\n",
    "        \"\"\"\n",
    "        Initializes the agent with a state and model configuration.\n",
    "\n",
    "        Parameters:\n",
    "        state (AgentGraphState): The initial state of the agent, containing necessary context and data.\n",
    "        model_config (dict): Configuration settings for the model, including endpoint, model name, temperature, etc.\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.model_endpoint = model_config.get(\"model_endpoint\")\n",
    "        self.model_name = model_config.get(\"model\")\n",
    "        self.temperature = model_config.get(\n",
    "            \"temperature\", 0\n",
    "        )  # Default temperature is 0\n",
    "        self.headers = model_config.get(\"headers\", {\"Content-Type\": \"application/json\"})\n",
    "        self.stop = model_config.get(\"stop\")\n",
    "\n",
    "    def update_state(self, key: str, value: any):\n",
    "        \"\"\"\n",
    "        Updates the agent's state with a new key-value pair.\n",
    "\n",
    "        Parameters:\n",
    "        key (str): The key in the state dictionary to update.\n",
    "        value (any): The new value to associate with the specified key.\n",
    "        \"\"\"\n",
    "        if key in self.state:\n",
    "            self.state[key] = value\n",
    "        else:\n",
    "            print(f\"Warning: Attempting to update a non-existing state key '{key}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility Functions\n",
    "\n",
    "Utility functions are auxiliary functions that assist with various common tasks within the notebook. They help keep the codebase clean and modular by encapsulating frequently used logic in separate functions. In this case, we have two utility functions: `check_for_content` and `get_current_utc_datetime`.\n",
    "\n",
    "- `check_for_content`: This function checks if a variable has a content attribute and returns its value if it exists. This is useful for handling different data types that may or may not have a content attribute.\n",
    "- `get_current_utc_datetime`: This function returns the current date and time in UTC format. This can be useful for timestamping events or logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# Check if an attribute of the state dict has content\n",
    "def check_for_content(var):\n",
    "    \"\"\"\n",
    "    Checks if the provided variable has a 'content' attribute and returns it.\n",
    "\n",
    "    Parameters:\n",
    "    var (Any): The variable to check.\n",
    "\n",
    "    Returns:\n",
    "    Any: The 'content' attribute if it exists, otherwise the original variable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return var.content\n",
    "    except AttributeError:\n",
    "        return var\n",
    "\n",
    "\n",
    "# Get the current date and time in UTC\n",
    "def get_current_utc_datetime():\n",
    "    \"\"\"\n",
    "    Returns the current date and time in UTC.\n",
    "\n",
    "    Returns:\n",
    "    str: The current date and time in UTC, formatted as 'YYYY-MM-DD HH:MM:SS UTC'.\n",
    "    \"\"\"\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    return now_utc.strftime(\"%Y-%m-%d %H:%M:%S UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PlannerAgent\n",
    "\n",
    "In this section, we define the `planner_prompt_template` and the `PlannerAgent` class. The `planner_prompt_template` is a string template that sets the context and expectations for the planner agent's response. It guides the agent in generating a comprehensive plan to help answer a given research question. The planner's responsibilities include identifying the most relevant search term, outlining an overall strategy, and providing additional information or filters for a thorough search.\n",
    "\n",
    "The `PlannerAgent` class extends the base `Agent` class and implements specific functionality for the planning task. It uses the provided template to format its requests to the language model and processes the model's responses. The class includes methods like `think`, which are used to generate and retrieve the agent's outputs based on the research question and any feedback received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for guiding the planner agent's response\n",
    "planner_prompt_template = \"\"\"\n",
    "You are a planner. Your responsibility is to create a comprehensive plan to help your team answer a research question. \n",
    "Questions may vary from simple to complex, multi-step queries. Your plan should provide appropriate guidance for your \n",
    "team to use an internet search engine effectively.\n",
    "\n",
    "Focus on highlighting the most relevant search term to start with, as another team member will use your suggestions \n",
    "to search for relevant information.\n",
    "\n",
    "If you receive feedback, you must adjust your plan accordingly. Here is the feedback received:\n",
    "Feedback: {feedback}\n",
    "\n",
    "Current date and time:\n",
    "{datetime}\n",
    "\n",
    "Your response must take the following JSON format:\n",
    "\n",
    "    \"search_term\": \"The most relevant search term to start with\",\n",
    "    \"overall_strategy\": \"The overall strategy to guide the search process\",\n",
    "    \"additional_information\": \"Any additional information to guide the search, including other search terms or filters\"\n",
    "\"\"\"\n",
    "\n",
    "# JSON schema for the planner's response\n",
    "planner_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"search_term\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The most relevant search term to start with\",\n",
    "        },\n",
    "        \"overall_strategy\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The overall strategy to guide the search process\",\n",
    "        },\n",
    "        \"additional_information\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Any additional information to guide the search, including other search terms or filters\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"search_term\", \"overall_strategy\", \"additional_information\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlannerAgent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "class PlannerAgent(Agent):\n",
    "    \n",
    "    def invoke(\n",
    "        self,\n",
    "        research_question: str,\n",
    "        prompt: str = planner_prompt_template,\n",
    "        feedback: any = None,\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Generates a response from the model based on the provided prompt.\n",
    "\n",
    "        Parameters:\n",
    "        research_question (str): The research question the planner agent needs to address.\n",
    "        prompt (str): The template used to generate the system prompt.\n",
    "        feedback (callable or str): Feedback received to adjust the planning process.\n",
    "\n",
    "        Returns:\n",
    "        dict: The updated state of the agent after processing the response.\n",
    "        \"\"\"\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        planner_prompt = prompt.format(\n",
    "            feedback=feedback_value, datetime=get_current_utc_datetime()\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": planner_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Research question: {research_question}\"},\n",
    "        ]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"format\": \"json\",\n",
    "            \"prompt\": messages[1][\"content\"],\n",
    "            \"system\": messages[0][\"content\"],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.model_endpoint, headers=self.headers, data=json.dumps(payload)\n",
    "            )\n",
    "            response_json = response.json()\n",
    "            response_content = json.loads(response_json.get(\"response\", \"{}\"))\n",
    "            response_formatted = HumanMessage(content=json.dumps(response_content))\n",
    "\n",
    "            self.update_state(\"planner_response\", response_formatted)\n",
    "            print(colored(f\"Planner 👩🏿‍💻: {response_formatted}\", \"cyan\"))\n",
    "            return self.state\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error in invoking model! {str(e)}\")\n",
    "            return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/gsampaio/redhat/ai/llm-agents/.conda/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.name\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name\n",
    "\n",
    "tools = [wiki, arxiv]\n",
    "\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query., args: {{'query': {{'title': 'Query', 'description': 'query to look up on wikipedia', 'type': 'string'}}}}\n",
      "arxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query., args: {{'query': {{'title': 'Query', 'description': 'search query to look up', 'type': 'string'}}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "tools_description = (\n",
    "    render_text_description_and_args(tools).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    ")\n",
    "\n",
    "print(tools_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_prompt_template = \"\"\"\n",
    "You are designed to help with a variety of tasks, from answering questions \\\n",
    "    to providing summaries to other types of analyses.\n",
    "\n",
    "## Tools\n",
    "You have access to a wide variety of tools. You are responsible for using\n",
    "the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "This may require breaking the task into subtasks and using different tools\n",
    "to complete each subtask.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_description}\n",
    "\n",
    "Return your findings in the following json format:\n",
    "\n",
    "    \"selected_tool\": \"The exact tool you choose to perfom the action\",\n",
    "    \"keyword\": \"The exact term that we are going to search\",\n",
    "    \"description\": \"A brief description of the page\",\n",
    "    \"reason_for_selection\": \"Why you selected this page\"\n",
    "\n",
    "\n",
    "Adjust your selection based on any feedback received:\n",
    "Feedback: {feedback}\n",
    "\n",
    "\n",
    "Consider this information when making your new selection.\n",
    "\n",
    "Current date and time:\n",
    "{datetime}\n",
    "\"\"\"\n",
    "\n",
    "selector_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"selected_tool\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The exact URL of the page you selected\",\n",
    "        },\n",
    "        \"description\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A brief description of the page\",\n",
    "        },\n",
    "        \"reason_for_selection\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Why you selected this page\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"selected_tool\", \"description\", \"reason_for_selection\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolsAgent(Agent):\n",
    "    def invoke(\n",
    "        self,\n",
    "        research_question: str,\n",
    "        prompt: str = selector_prompt_template,\n",
    "        feedback: any = None,\n",
    "        tools_description: str = tools_description,\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Generates a response from the model based on the provided prompt.\n",
    "\n",
    "        Parameters:\n",
    "        research_question (str): The research question the planner agent needs to address.\n",
    "        prompt (str): The template used to generate the system prompt.\n",
    "        feedback (callable or str): Feedback received to adjust the planning process.\n",
    "\n",
    "        Returns:\n",
    "        dict: The updated state of the agent after processing the response.\n",
    "        \"\"\"\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        tools_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            tools_description=tools_description,\n",
    "            datetime=get_current_utc_datetime(),\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": tools_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Research question: {research_question}\"},\n",
    "        ]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"format\": \"json\",\n",
    "            \"prompt\": messages[1][\"content\"],\n",
    "            \"system\": messages[0][\"content\"],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.model_endpoint, headers=self.headers, data=json.dumps(payload)\n",
    "            )\n",
    "            response_json = response.json()\n",
    "            response_content = json.loads(response_json.get(\"response\", \"{}\"))\n",
    "            response_formatted = HumanMessage(content=json.dumps(response_content))\n",
    "\n",
    "            self.update_state(\"tools_response\", response_formatted)\n",
    "            print(colored(f\"Tools 🔧: {response_formatted}\", \"yellow\"))\n",
    "            return self.state\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error in invoking model! {str(e)}\")\n",
    "            return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. End Node\n",
    "\n",
    "The `EndNodeAgent` class is a specialized agent that marks the conclusion of the workflow in the agent graph. It extends the base `Agent` class and is primarily responsible for updating the state to indicate the end of the process. This agent is useful for workflows that require a clear termination point, ensuring that the system knows when all processing is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndNodeAgent(Agent):\n",
    "    def invoke(self) -> AgentGraphState:\n",
    "        \"\"\"\n",
    "        Marks the end of the workflow by updating the state.\n",
    "\n",
    "        This method updates the 'end_chain' key in the state to signify that\n",
    "        the workflow has reached its conclusion. It can be used to perform any\n",
    "        finalization tasks or simply to denote that the agent has completed its role.\n",
    "\n",
    "        Returns:\n",
    "        AgentGraphState: The updated state of the agent.\n",
    "        \"\"\"\n",
    "        self.update_state(\"end_chain\", \"end_chain\")\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# This a helper class we have that is useful for running tools\n",
    "# It takes in an agent action and calls that tool and returns the result\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(data):\n",
    "    \"\"\"\n",
    "    Executes the tool selected by the ToolsAgent.\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): The data containing the agent's state, including the selected tool.\n",
    "\n",
    "    Returns:\n",
    "    dict: Updated state with the tool execution results.\n",
    "    \"\"\"\n",
    "    # Get the most recent agent_outcome - this is the key added in the ToolsAgent\n",
    "    tools_response = data[\"tools_response\"][-1]\n",
    "    if isinstance(tools_response, HumanMessage):\n",
    "        tools_response_json = json.loads(tools_response.content)\n",
    "        selected_tool = tools_response_json.get(\"selected_tool\")\n",
    "        keyword = tools_response_json.get(\"keyword\")\n",
    "        if selected_tool:\n",
    "            # Execute the selected tool and store the output\n",
    "            print(colored(f\"Selected Tool 🪛: {selected_tool} Keyword:{keyword}\", \"red\"))\n",
    "            invocation = ToolInvocation(tool=selected_tool, tool_input=keyword)\n",
    "            output = tool_executor.invoke(invocation)\n",
    "            print(colored(f\"Result: {output}\", \"green\"))\n",
    "            # Update the state with the tool's response\n",
    "            new_tools_response = SystemMessage(content=output)\n",
    "            return {\"research_response\": new_tools_response}\n",
    "        else:\n",
    "            print(\"Error: No selected_tool specified in the HumanMessage.\")\n",
    "            return {\"tools_response\": tools_response}\n",
    "    else:\n",
    "        print(\"Error: tools_response is not of type HumanMessage.\")\n",
    "        return {\"tools_response\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(data):\n",
    "    \"\"\"\n",
    "    Determines the next step in the workflow based on the agent's output.\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): The data containing the agent's state.\n",
    "\n",
    "    Returns:\n",
    "    str: The next node to execute ('continue' for tool execution, 'end' to finish).\n",
    "    \"\"\"\n",
    "    # Check if the tools_response contains a final answer or indication to stop\n",
    "\n",
    "    latest_response = data.get(\"research_response\", [])\n",
    "\n",
    "    if latest_response:\n",
    "        return \"end\"\n",
    "    # Default to continue if no end condition is met\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating and Compiling the Agent Graph\n",
    "\n",
    "In this section, we define the structure and flow of the agent-based system using the `StateGraph` class from the `langgraph` library. The graph consists of nodes, each representing a specific agent, and edges, which define the flow or sequence of operations. This setup enables the modeling of complex workflows where different agents can interact and pass information.\n",
    "\n",
    "- **`create_graph`:** This function initializes the `StateGraph` with a specific state structure (`AgentGraphState`). It then adds nodes for the `PlannerAgent` and `EndNodeAgent`, specifying the operations these agents should perform. The function sets the \"planner\" node as the entry point and the \"end\" node as the finish point, with an edge connecting them to define the workflow sequence.\n",
    "- **`compile_workflow`:** This function compiles the defined graph into a workflow that can be executed. The compiled workflow manages the execution of the nodes in the defined order, handling the flow of data and control through the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Creates and configures the state graph for the agent workflow.\n",
    "\n",
    "    This function initializes the graph, adds the necessary nodes (agents), and\n",
    "    sets up the edges defining the flow of the workflow.\n",
    "\n",
    "    Returns:\n",
    "    StateGraph: The configured state graph for the workflow.\n",
    "    \"\"\"\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "    graph.add_node(\n",
    "        \"planner\",\n",
    "        lambda state: PlannerAgent(\n",
    "            state=state,\n",
    "            model_config=ollama_config,\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(\n",
    "                state=state, state_key=\"reviewer_latest\"\n",
    "            ),\n",
    "            prompt=planner_prompt_template,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"tools\",\n",
    "        lambda state: ToolsAgent(\n",
    "            state=state,\n",
    "            model_config=ollama_config,\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(\n",
    "                state=state, state_key=\"reviewer_latest\"\n",
    "            ),\n",
    "            prompt=selector_prompt_template,\n",
    "            tools_description=tools_description,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    graph.add_node(\"execute_tools\", execute_tools)\n",
    "\n",
    "    graph.add_node(\n",
    "        \"end\",\n",
    "        lambda state: EndNodeAgent(\n",
    "            state=state,\n",
    "            model_config=ollama_config,\n",
    "        ).invoke(),\n",
    "    )\n",
    "\n",
    "    # Set the entry and finish points for the workflow\n",
    "    graph.set_entry_point(\"planner\")\n",
    "    graph.set_finish_point(\"end\")\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(\"planner\", \"tools\")\n",
    "    graph.add_edge(\"tools\", \"execute_tools\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"execute_tools\", should_continue, {\"continue\": \"planner\", \"end\": \"end\"}\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def compile_workflow(graph: StateGraph):\n",
    "    \"\"\"\n",
    "    Compiles the state graph into an executable workflow.\n",
    "\n",
    "    This function compiles the graph, enabling the defined nodes and edges to\n",
    "    be executed in sequence as per the workflow's logic.\n",
    "\n",
    "    Parameters:\n",
    "    graph (StateGraph): The state graph defining the workflow.\n",
    "\n",
    "    Returns:\n",
    "    Any: The compiled workflow ready for execution.\n",
    "    \"\"\"\n",
    "    workflow = graph.compile()\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Workflow\n",
    "\n",
    "In this final section, we execute the workflow defined in the agent graph. We start by creating the graph using the `create_graph` function and then compiling it into an executable workflow with `compile_workflow`. The workflow is then run with specific inputs and configurations.\n",
    "\n",
    "- **`graph = create_graph()`:** This initializes the graph structure, including all nodes and edges as defined previously.\n",
    "- **`workflow = compile_workflow(graph)`:** This compiles the graph into a runnable workflow, preparing it for execution.\n",
    "- **`iterations = 10`:** This variable sets the recursion limit for the workflow, determining how many iterations the workflow should allow.\n",
    "- **`verbose = True`:** If set to `True`, the system will print detailed information about each state change during the workflow execution.\n",
    "- **`query = \"Who's the president of the USA?\"`:** The research question provided as input to the workflow, which the planner agent will process.\n",
    "- **`dict_inputs = {\"research_question\": query}`:** A dictionary containing the initial inputs to the workflow, including the research question.\n",
    "- **`limit = {\"recursion_limit\": iterations}`:** This sets the limit for the number of iterations, preventing infinite loops or excessive processing.\n",
    "\n",
    "The loop iterates over the events generated by the workflow, printing the state at each step if `verbose` is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n",
      "\u001b[36mPlanner 👩🏿‍💻: content='{\"search_term\": \"current president of the usa\", \"overall_strategy\": \"Use a specific date filter (e.g., 2024) and limit results to \\'news\\' articles or official government websites for the most accurate information.\", \"additional_information\": \"Use quotes around the search term if searching for an exact phrase. You can also use alternative phrases like \\'us president now\\' or \\'president of the united states 2024\\' to get more results.\"}'\u001b[0m\n",
      "\n",
      "State Dictionary: {'planner': {'research_question': \"Who's the current president of the USA?\", 'planner_response': HumanMessage(content='{\"search_term\": \"current president of the usa\", \"overall_strategy\": \"Use a specific date filter (e.g., 2024) and limit results to \\'news\\' articles or official government websites for the most accurate information.\", \"additional_information\": \"Use quotes around the search term if searching for an exact phrase. You can also use alternative phrases like \\'us president now\\' or \\'president of the united states 2024\\' to get more results.\"}'), 'tools_response': [], 'research_response': [], 'end_chain': []}}\n",
      "\u001b[33mTools 🔧: content='{\"selected_tool\": \"wikipedia\", \"keyword\": \"current president of the United States\", \"description\": \"The page will provide information about the current head of state and government of the United States, including their term in office, political party affiliation, and notable accomplishments.\", \"reason_for_selection\": \"Wikipedia is a reliable source for general knowledge questions like this one.\"}'\u001b[0m\n",
      "\n",
      "State Dictionary: {'tools': {'research_question': \"Who's the current president of the USA?\", 'planner_response': [HumanMessage(content='{\"search_term\": \"current president of the usa\", \"overall_strategy\": \"Use a specific date filter (e.g., 2024) and limit results to \\'news\\' articles or official government websites for the most accurate information.\", \"additional_information\": \"Use quotes around the search term if searching for an exact phrase. You can also use alternative phrases like \\'us president now\\' or \\'president of the united states 2024\\' to get more results.\"}', id='31c6ab71-4782-494b-a2fa-404751014c57')], 'tools_response': HumanMessage(content='{\"selected_tool\": \"wikipedia\", \"keyword\": \"current president of the United States\", \"description\": \"The page will provide information about the current head of state and government of the United States, including their term in office, political party affiliation, and notable accomplishments.\", \"reason_for_selection\": \"Wikipedia is a reliable source for general knowledge questions like this one.\"}'), 'research_response': [], 'end_chain': []}}\n",
      "\u001b[31mSelected Tool 🪛: wikipedia Keyword:current president of the United States\u001b[0m\n",
      "\u001b[32mResult: Page: President of the United States\n",
      "Summary: The president of the United States (POTUS) is the head of state and head of government of the United States of America. The president directs the executiv\u001b[0m\n",
      "\n",
      "State Dictionary: {'execute_tools': {'research_response': SystemMessage(content='Page: President of the United States\\nSummary: The president of the United States (POTUS) is the head of state and head of government of the United States of America. The president directs the executiv', id='1db49481-65bd-4151-b8b6-012ca6d18f2f')}}\n",
      "\n",
      "State Dictionary: {'end': {'research_question': \"Who's the current president of the USA?\", 'planner_response': [HumanMessage(content='{\"search_term\": \"current president of the usa\", \"overall_strategy\": \"Use a specific date filter (e.g., 2024) and limit results to \\'news\\' articles or official government websites for the most accurate information.\", \"additional_information\": \"Use quotes around the search term if searching for an exact phrase. You can also use alternative phrases like \\'us president now\\' or \\'president of the united states 2024\\' to get more results.\"}', id='31c6ab71-4782-494b-a2fa-404751014c57')], 'tools_response': [HumanMessage(content='{\"selected_tool\": \"wikipedia\", \"keyword\": \"current president of the United States\", \"description\": \"The page will provide information about the current head of state and government of the United States, including their term in office, political party affiliation, and notable accomplishments.\", \"reason_for_selection\": \"Wikipedia is a reliable source for general knowledge questions like this one.\"}', id='6cb0834a-d3a7-4394-82c9-951fe532ddab')], 'research_response': [SystemMessage(content='Page: President of the United States\\nSummary: The president of the United States (POTUS) is the head of state and head of government of the United States of America. The president directs the executiv', id='1db49481-65bd-4151-b8b6-012ca6d18f2f')], 'end_chain': 'end_chain'}}\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = compile_workflow(graph)\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "verbose = True\n",
    "query = \"Who's the current president of the USA?\"\n",
    "dict_inputs = {\"research_question\": query}\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, limit):\n",
    "    if verbose:\n",
    "        print(\"\\nState Dictionary:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
