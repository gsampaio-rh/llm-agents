{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain ReAct Agent\n",
    "\n",
    "This notebook is designed to introduce you to LangChain, a powerful tool for building applications that use large language models (LLMs) to process and generate human-like text. In this tutorial, we will create a simple agent using LangChain. An \"agent\" in this context is a program that can understand and respond to text input, much like a conversation with a person.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **What is LangChain?**\n",
    "2. **What is an LLM (Large Language Model)?**\n",
    "3. **What is an agent in AI?**\n",
    "4. **How to set up a LangChain agent using Python**\n",
    "5. **How to handle errors in agent responses**\n",
    "\n",
    "Let's start by understanding some basic concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "### 1. What is LangChain?\n",
    "\n",
    "**LangChain** is a library that helps developers create applications using large language models (LLMs). These models can perform various tasks, like answering questions, generating text, and more, by understanding and processing human language.\n",
    "\n",
    "### 2. What is a Large Language Model (LLM)?\n",
    "\n",
    "An **LLM** is a type of artificial intelligence model that has been trained on a large amount of text data. It can understand and generate text based on the input it receives. LLMs are powerful because they can understand context and produce human-like responses.\n",
    "\n",
    "### 3. What is an Agent in AI?\n",
    "\n",
    "An **agent** is a program that can perform tasks autonomously. In the context of AI and LangChain, an agent can receive text input, process it using an LLM, and generate appropriate responses or perform actions. For example, an agent could answer questions, do calculations, or fetch data from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "Before we can create our agent, we need to install some necessary libraries. These libraries will give us the tools we need to build and run our agent.\n",
    "\n",
    "### Install Necessary Libraries\n",
    "\n",
    "To use this notebook, you need to install the following Python libraries:\n",
    "- `langchain`: The core library for creating and managing agents.\n",
    "- `langchain-ollama`: An extension for integrating specific language models.\n",
    "- `langchain-community`: A set of tools and utilities for working with LangChain.\n",
    "- `numexpr`: A fast numerical expression evaluator for NumPy.\n",
    "\n",
    "Run the following command to install these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.11/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain-ollama in ./.conda/lib/python3.11/site-packages (0.1.0)\n",
      "Requirement already satisfied: langchain-community in ./.conda/lib/python3.11/site-packages (0.2.10)\n",
      "Requirement already satisfied: numexpr in ./.conda/lib/python3.11/site-packages (2.10.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.23)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.11/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in ./.conda/lib/python3.11/site-packages (from langchain-ollama) (0.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.conda/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./.conda/lib/python3.11/site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "%pip install langchain langchain-ollama langchain-community numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your First LangChain Agent\n",
    "\n",
    "Now that we have our environment set up, let's create our first LangChain agent. We'll use a pre-trained LLM called \"Ollama\" and add a simple math tool to our agent.\n",
    "\n",
    "### Import Necessary Modules\n",
    "\n",
    "We need to import some modules from the libraries we installed. These modules will help us create and manage our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/llm-agents/.conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Set up the Ollama LLM model, specifying the model type\n",
    "llm = OllamaLLM(model=\"mistral\")\n",
    "\n",
    "# Load tools and create an agent\n",
    "# The \"llm-math\" tool allows the agent to perform mathematical calculations\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# Initialize the agent with the loaded tools and language model\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,  # This makes the agent's actions more transparent\n",
    "    handle_parsing_errors=True  # This helps handle any errors in understanding the agent's output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Agent\n",
    "\n",
    "Now that we have our agent set up, let's see it in action. We'll ask the agent a simple question and see how it responds.\n",
    "\n",
    "### Example Query with Error Handling\n",
    "\n",
    "When interacting with AI agents, it's important to handle any errors that might occur. For example, the agent might not understand a question correctly. We'll demonstrate how to handle such errors gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To answer this question, I need to perform an addition operation. The tool I will use for that is Calculator.\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 5 + 5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The answer to 5 + 5 is 10.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is 5 + 5?', 'output': 'The answer to 5 + 5 is 10.'}\n"
     ]
    }
   ],
   "source": [
    "# Standard LLM Query with error handling for output parsing errors\n",
    "try:\n",
    "    # Ask the agent a simple math question\n",
    "    response = agent.invoke(\"What is 5 + 5?\", handle_parsing_errors=True)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    # Print any errors that occur\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this introductory notebook, we explored the basics of LangChain and how to set up a simple agent using the Ollama LLM and a math tool. We covered the essential concepts and steps needed to create and query an AI agent, along with handling potential errors. This foundational knowledge can be expanded upon to create more complex and capable agents for a variety of tasks.\n",
    "\n",
    "Feel free to experiment with different questions and tools to see what your agent can do!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
