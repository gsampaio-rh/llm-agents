{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agents with Ollama: A Step-by-Step Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "import operator\n",
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_prompt_template = \"\"\"\n",
    "You are an agent with access to a toolbox. Given a user query, \n",
    "you will determine which tool, if any, is best suited to answer the query. \n",
    "You will generate the following JSON response:\n",
    "\n",
    "\"tool_choice\": \"name_of_the_tool\",\n",
    "\"tool_input\": \"inputs_to_the_tool\"\n",
    "\n",
    "- `tool_choice`: The name of the tool you want to use. It must be a tool from your toolbox \n",
    "                or \"no tool\" if you do not need to use a tool.\n",
    "- `tool_input`: The specific inputs required for the selected tool. \n",
    "                If no tool, just provide a response to the query.\n",
    "\n",
    "Here is a list of your tools along with their descriptions:\n",
    "{tool_descriptions}\n",
    "\n",
    "Please make a decision based on the provided user query and the available tools.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ollama_model(model, system_prompt, temperature=0, stop=None):\n",
    "    \"\"\"\n",
    "    Sets up the Ollama model configuration.\n",
    "\n",
    "    Parameters:\n",
    "    model (str): The name of the model to use.\n",
    "    system_prompt (str): The system prompt to use.\n",
    "    temperature (float): The temperature setting for the model.\n",
    "    stop (str): The stop token for the model.\n",
    "\n",
    "    Returns:\n",
    "    dict: Configuration for the Ollama model.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"model_endpoint\": \"http://localhost:11434/api/generate\",\n",
    "        \"model\": model,\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"headers\": {\"Content-Type\": \"application/json\"},\n",
    "        \"stop\": stop,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example configuration\n",
    "ollama_config = setup_ollama_model(\n",
    "    model=\"mistral\", system_prompt=agent_system_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_calculator(input_str):\n",
    "    \"\"\"\n",
    "    Perform a numeric operation on two numbers based on the input string.\n",
    "\n",
    "    Parameters:\n",
    "    input_str (str): A JSON string representing a dictionary with keys 'num1', 'num2', and 'operation'.\n",
    "                     Example: '{\"num1\": 5, \"num2\": 3, \"operation\": \"add\"}' or \"{'num1': 67869, 'num2': 9030393, 'operation': 'divide'}\"\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted result of the operation.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If an error occurs during the operation (e.g., division by zero).\n",
    "    ValueError: If an unsupported operation is requested or input is invalid.\n",
    "    \"\"\"\n",
    "    # Clean and parse the input string\n",
    "    try:\n",
    "        # Replace single quotes with double quotes\n",
    "        input_str_clean = input_str.replace(\"'\", '\"')\n",
    "        # Remove any extraneous characters such as trailing quotes\n",
    "        input_str_clean = input_str_clean.strip().strip('\"')\n",
    "\n",
    "        input_dict = json.loads(input_str_clean)\n",
    "        num1 = input_dict[\"num1\"]\n",
    "        num2 = input_dict[\"num2\"]\n",
    "        operation = input_dict[\"operation\"]\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        return str(e), \"Invalid input format. Please provide a valid JSON string.\"\n",
    "\n",
    "    # Define the supported operations\n",
    "    operations = {\n",
    "        \"add\": operator.add,\n",
    "        \"subtract\": operator.sub,\n",
    "        \"multiply\": operator.mul,\n",
    "        \"divide\": operator.truediv,\n",
    "        \"floor_divide\": operator.floordiv,\n",
    "        \"modulus\": operator.mod,\n",
    "        \"power\": operator.pow,\n",
    "        \"lt\": operator.lt,\n",
    "        \"le\": operator.le,\n",
    "        \"eq\": operator.eq,\n",
    "        \"ne\": operator.ne,\n",
    "        \"ge\": operator.ge,\n",
    "        \"gt\": operator.gt,\n",
    "    }\n",
    "\n",
    "    # Check if the operation is supported\n",
    "    if operation in operations:\n",
    "        try:\n",
    "            # Perform the operation\n",
    "            result = operations[operation](num1, num2)\n",
    "            result_formatted = (\n",
    "                f\"\\n\\nThe answer is: {result}.\\nCalculated with basic_calculator.\"\n",
    "            )\n",
    "            return result_formatted\n",
    "        except Exception as e:\n",
    "            return str(e), \"\\n\\nError during operation execution.\"\n",
    "    else:\n",
    "        return \"\\n\\nUnsupported operation. Please provide a valid operation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_string(input_string):\n",
    "    \"\"\"\n",
    "    Reverse the given string.\n",
    "\n",
    "    Parameters:\n",
    "    input_string (str): The string to be reversed.\n",
    "\n",
    "    Returns:\n",
    "    str: The reversed string.\n",
    "    \"\"\"\n",
    "    # Reverse the string using slicing\n",
    "    reversed_string = input_string[::-1]\n",
    "\n",
    "    reversed_string = f\"The reversed string is: {reversed_string}\\n\\n.Executed using the reverse_string function.\"\n",
    "    # print (f\"DEBUG: reversed_string: {reversed_string}\")\n",
    "    return reversed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tools(tools):\n",
    "    \"\"\"\n",
    "    Stores the tools and returns their descriptions.\n",
    "\n",
    "    Parameters:\n",
    "    tools (list): List of tool functions.\n",
    "\n",
    "    Returns:\n",
    "    str: Description of the tools.\n",
    "    \"\"\"\n",
    "    tools_dict = {tool.__name__: tool.__doc__ for tool in tools}\n",
    "    tools_description = \"\\n\".join(\n",
    "        f'{name}: \"{desc}\"' for name, desc in tools_dict.items()\n",
    "    )\n",
    "    return tools_description\n",
    "\n",
    "\n",
    "# Define tools\n",
    "tools = [basic_calculator, reverse_string]\n",
    "tools_description = prepare_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, config):\n",
    "    \"\"\"\n",
    "    Generates a response from the Ollama model based on the provided prompt.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): The user query.\n",
    "    config (dict): The Ollama model configuration.\n",
    "\n",
    "    Returns:\n",
    "    dict: The response from the model.\n",
    "    \"\"\"\n",
    "    agent_system_prompt = agent_system_prompt_template.format(\n",
    "        tool_descriptions=tools_description\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": config[\"model\"],\n",
    "        \"format\": \"json\",\n",
    "        \"prompt\": prompt,\n",
    "        \"system\": agent_system_prompt,\n",
    "        \"stream\": False,\n",
    "        \"temperature\": config[\"temperature\"],\n",
    "        \"stop\": config[\"stop\"],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            config[\"model_endpoint\"],\n",
    "            headers=config[\"headers\"],\n",
    "            data=json.dumps(payload),\n",
    "        )\n",
    "        response_json = response.json()\n",
    "        response_dict = json.loads(response_json[\"response\"])\n",
    "\n",
    "        print(f\"\\n\\nResponse from Ollama model: {response_dict}\")\n",
    "        return response_dict\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error in invoking model! {str(e)}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool(response, tools):\n",
    "    \"\"\"\n",
    "    Executes the appropriate tool based on the model's response.\n",
    "\n",
    "    Parameters:\n",
    "    response (dict): The model's response.\n",
    "    tools (list): List of available tool functions.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    tool_choice = response.get(\"tool_choice\")\n",
    "    tool_input = response.get(\"tool_input\")\n",
    "\n",
    "    for tool in tools:\n",
    "        if tool.__name__ == tool_choice:\n",
    "            result = tool(tool_input)\n",
    "            print(colored(result, \"cyan\"))\n",
    "            return\n",
    "\n",
    "    print(colored(tool_input, \"cyan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response from Ollama model: {'tool_choice': 'basic_calculator', 'tool_input': '{\"num1\": 5, \"num2\": 5, \"operation\": \"add\"}'}\n",
      "\u001b[36m\n",
      "\n",
      "The answer is: 10.\n",
      "Calculated with basic_calculator.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is 5+5?\"\n",
    "response = generate_response(prompt, ollama_config)\n",
    "execute_tool(response, tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
