{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - pytorch\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faster-whisper in ./.conda/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: av<13,>=11.0 in ./.conda/lib/python3.11/site-packages (from faster-whisper) (12.3.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in ./.conda/lib/python3.11/site-packages (from faster-whisper) (4.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in ./.conda/lib/python3.11/site-packages (from faster-whisper) (0.24.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in ./.conda/lib/python3.11/site-packages (from faster-whisper) (0.19.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in ./.conda/lib/python3.11/site-packages (from faster-whisper) (1.18.1)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (69.5.1)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in ./.conda/lib/python3.11/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (24.1)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
      "Requirement already satisfied: coloredlogs in ./.conda/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.conda/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
      "Requirement already satisfied: protobuf in ./.conda/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.27.2)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.conda/lib/python3.11/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/lib/python3.11/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydub in ./.conda/lib/python3.11/site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# %conda install pytorch::pytorch torchvision torchaudio -c pytorch\n",
    "%conda install pandas\n",
    "%pip install faster-whisper\n",
    "%pip install pydub\n",
    "# %conda install transformers datasets evaluate accelerate\n",
    "# %conda install pandas matplotlib seaborn ipywidgets\n",
    "# %conda install scikit-learn -c conda-forge scikit-learn\n",
    "# %pip install bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-14.5-arm64-arm-64bit\n",
      "PyTorch Version: 2.4.0\n",
      "\n",
      "Python 3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]\n",
      "NVIDIA/CUDA GPU is NOT AVAILABLE\n",
      "MPS (Apple Metal) is AVAILABLE\n",
      "Target device is mps\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# path to mp3 audio files\n",
    "path_to_mp3_audio_folder = \"mp3_audio_files/\"\n",
    "\n",
    "# path to transcripts\n",
    "path_to_transcripts_folder = path_to_mp3_audio_folder + \"transcripts/\"\n",
    "\n",
    "if not Path(path_to_transcripts_folder).is_dir():\n",
    "    Path(path_to_transcripts_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, PosixPath('mp3_audio_files/lesson1_of_RAG_course_with_DeepLearningAI.mp3'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path(path_to_mp3_audio_folder).glob(\"**/*\")\n",
    "mp3_audio_files = [x for x in p if x.is_file() and \".mp3\" in x.name]\n",
    "len(mp3_audio_files), mp3_audio_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/llm-agents/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# model_size = \"large-v2\"\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# get device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda:0\":\n",
    "    # Run on GPU with FP16\n",
    "    model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "    # or Run on GPU with INT8\n",
    "    # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "else:\n",
    "    # Run on CPU with INT8\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check GPU (cuda) or CPU\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# %%time\n",
    "\n",
    "for i, path_to_audio_file in enumerate(mp3_audio_files[:1]):\n",
    "\n",
    "    # get all audio segments\n",
    "    # from pydub.playback import play\n",
    "    segments, _ = model.transcribe(str(path_to_audio_file), beam_size=5, vad_filter=True)\n",
    "    # segments = list(segments)  # The transcription will actually run here.\n",
    "\n",
    "    # get audio language\n",
    "    # print(\"Detected language '%s' with probability %f with faster whisper\\n\" % (info.language, info.language_probability))\n",
    "\n",
    "    # save audio segments with start and end time, and transcript by audio segment\n",
    "    start_segments, end_segments, text_segments = list(), list(), list()\n",
    "    for segment in segments:\n",
    "        # print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "        start, end, text = segment.start, segment.end, segment.text\n",
    "        start_segments.append(start)\n",
    "        end_segments.append(end)\n",
    "        text_segments.append(text)\n",
    "\n",
    "    # save transcript into csv\n",
    "    df = pd.DataFrame()\n",
    "    df[\"start\"] = start_segments\n",
    "    df[\"end\"] = end_segments\n",
    "    df[\"text\"] = text_segments\n",
    "    path_to_audio_file_transcript = path_to_transcripts_folder + path_to_audio_file.name.replace(\".mp3\", \".csv\").replace(\".wav\", \".csv\")\n",
    "    df.to_csv(path_to_audio_file_transcript, encoding='utf-8', index=False)\n",
    "\n",
    "    if i % 2 == 0: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.78</td>\n",
       "      <td>9.78</td>\n",
       "      <td>Retrieval Augmented Generation, or RAG, has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.78</td>\n",
       "      <td>17.78</td>\n",
       "      <td>But to actually build and productionize a hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.78</td>\n",
       "      <td>23.78</td>\n",
       "      <td>to give the LM highly relevant context to gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.78</td>\n",
       "      <td>31.78</td>\n",
       "      <td>to help you efficiently iterate and improve y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.78</td>\n",
       "      <td>38.78</td>\n",
       "      <td>This course covers two advanced retrieval met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>267.78</td>\n",
       "      <td>268.78</td>\n",
       "      <td>Sounds great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>268.78</td>\n",
       "      <td>269.78</td>\n",
       "      <td>Let's get started.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>269.78</td>\n",
       "      <td>274.78</td>\n",
       "      <td>And I think you'll be able to really clean up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>274.78</td>\n",
       "      <td>276.78</td>\n",
       "      <td>Laughed on it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>276.78</td>\n",
       "      <td>277.78</td>\n",
       "      <td>Sweet.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start     end                                               text\n",
       "0     1.78    9.78   Retrieval Augmented Generation, or RAG, has b...\n",
       "1     9.78   17.78   But to actually build and productionize a hig...\n",
       "2    17.78   23.78   to give the LM highly relevant context to gen...\n",
       "3    23.78   31.78   to help you efficiently iterate and improve y...\n",
       "4    31.78   38.78   This course covers two advanced retrieval met...\n",
       "..     ...     ...                                                ...\n",
       "65  267.78  268.78                                      Sounds great.\n",
       "66  268.78  269.78                                 Let's get started.\n",
       "67  269.78  274.78   And I think you'll be able to really clean up...\n",
       "68  274.78  276.78                                     Laughed on it.\n",
       "69  276.78  277.78                                             Sweet.\n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download the Punkt tokenizer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the Punkt tokenizer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \" \".join(df[\"text\"].tolist()).replace(\"  \", \" \")\n",
    "\n",
    "# Tokenize the paragraph into sentences\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "        \n",
    "      \"\"\"\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "for sentence in sentences:\n",
    "    display(HTML(f\"{css} {sentence}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
