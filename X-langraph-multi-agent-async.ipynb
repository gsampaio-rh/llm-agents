{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "Before we dive into building our agent, we need to set up the necessary environment. This involves installing required packages and ensuring our Python environment is ready for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.1.15)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.22 in ./.conda/lib/python3.11/site-packages (from langgraph) (0.2.23)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.22->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install termcolor for colored terminal outputs\n",
    "%pip install termcolor langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated\n",
    "from datetime import datetime, timezone\n",
    "from termcolor import colored\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state object for the agent graph\n",
    "class AgentGraphState(TypedDict):\n",
    "    start_chain: Annotated[list, add_messages]\n",
    "    transcription_response: Annotated[list, add_messages]\n",
    "    portuguese_response: Annotated[list, add_messages]\n",
    "    spanish_response: Annotated[list, add_messages]\n",
    "    end_chain: Annotated[list, add_messages]\n",
    "\n",
    "# Function to retrieve specific parts of the agent state\n",
    "def get_agent_graph_state(state: AgentGraphState, state_key: str):\n",
    "\n",
    "    if state_key == \"transcription_all\":\n",
    "        return state[\"transcription_response\"]\n",
    "    elif state_key == \"transcription_latest\":\n",
    "        return (\n",
    "            state[\"transcription_response\"][-1]\n",
    "            if state[\"transcription_response\"]\n",
    "            else []\n",
    "        )\n",
    "\n",
    "    if state_key == \"portuguese_all\":\n",
    "        return state[\"portuguese_response\"]\n",
    "    elif state_key == \"portuguese_latest\":\n",
    "        return state[\"portuguese_response\"][-1] if state[\"portuguese_response\"] else []\n",
    "\n",
    "    if state_key == \"spanish_all\":\n",
    "        return state[\"spanish_response\"]\n",
    "    elif state_key == \"spanish_latest\":\n",
    "        return state[\"spanish_response\"][-1] if state[\"spanish_response\"] else []\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initial state setup\n",
    "state = {\n",
    "    \"start_chain\": [],\n",
    "    \"transcription_response\": [],\n",
    "    \"portuguese_response\": [],\n",
    "    \"spanish_response\": [],\n",
    "    \"end_chain\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "class TranscriptAgent:\n",
    "\n",
    "    def __init__(self, state: AgentGraphState, words: list):\n",
    "        self.state = state\n",
    "        self.words = words\n",
    "\n",
    "    async def invoke(self):\n",
    "        for word in self.words:\n",
    "            await asyncio.sleep(5)  # Simulate async operation\n",
    "            print(colored(f\"TRANSCRIPT_AGENT üìù: Processing word '{word}'\", \"cyan\"))\n",
    "            self.state[\"transcription_response\"].append(word)\n",
    "            yield self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    async def text_node_function(state):\n",
    "        agent = TranscriptAgent(\n",
    "            state=state, words=[\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"]\n",
    "        )\n",
    "        async for new_state in agent.invoke():\n",
    "            yield new_state\n",
    "\n",
    "    graph.add_node(\"text_node\", text_node_function)\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(START, \"text_node\")\n",
    "    graph.add_edge(\"text_node\", END)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def compile_workflow(graph: StateGraph):\n",
    "    workflow = graph.compile()\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n",
      "\u001b[35m{'event': 'on_chain_start', 'run_id': 'e04956fd-c97a-4141-86d7-6ee425f590d5', 'name': 'LangGraph', 'tags': [], 'metadata': {}, 'data': {'input': {'start_chain': 'start'}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_start', 'name': '__start__', 'run_id': '84b6259e-cfae-4723-9aec-474bf485678d', 'tags': ['graph:step:0', 'langsmith:hidden'], 'metadata': {'langgraph_step': 0, 'langgraph_node': '__start__', 'langgraph_triggers': ['__start__'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': 'start'}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_end', 'name': '__start__', 'run_id': '84b6259e-cfae-4723-9aec-474bf485678d', 'tags': ['graph:step:0', 'langsmith:hidden'], 'metadata': {'langgraph_step': 0, 'langgraph_node': '__start__', 'langgraph_triggers': ['__start__'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': 'start'}, 'output': {'start_chain': 'start'}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_start', 'name': 'text_node', 'run_id': 'b8e365b9-2c00-49bc-b55e-8c55b550ee9f', 'tags': ['graph:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_start', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'hello'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'world'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'this'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'is'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'a'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[36mTRANSCRIPT_AGENT üìù: Processing word 'test'\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_end', 'name': 'text_node', 'run_id': 'b70a2c72-ff6a-43db-b0be-658542670241', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}, 'output': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_start', 'name': 'ChannelWrite<text_node,start_chain,transcription_response,end_chain>', 'run_id': 'ecae557e-7384-4f0e-b424-ea02e8b90c77', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_end', 'name': 'ChannelWrite<text_node,start_chain,transcription_response,end_chain>', 'run_id': 'ecae557e-7384-4f0e-b424-ea02e8b90c77', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}, 'output': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'name': 'text_node', 'run_id': 'b8e365b9-2c00-49bc-b55e-8c55b550ee9f', 'tags': ['graph:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'chunk': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_end', 'name': 'text_node', 'run_id': 'b8e365b9-2c00-49bc-b55e-8c55b550ee9f', 'tags': ['graph:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'text_node', 'langgraph_triggers': ['start:text_node'], 'langgraph_task_idx': 0, 'thread_ts': '1ef50c1e-82cf-683a-bffe-e98172474940'}, 'data': {'input': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}, 'output': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_stream', 'run_id': 'e04956fd-c97a-4141-86d7-6ee425f590d5', 'tags': [], 'metadata': {}, 'name': 'LangGraph', 'data': {'chunk': {'text_node': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}}, 'parent_ids': []}\u001b[0m\n",
      "\u001b[35m{'event': 'on_chain_end', 'name': 'LangGraph', 'run_id': 'e04956fd-c97a-4141-86d7-6ee425f590d5', 'tags': [], 'metadata': {}, 'data': {'output': {'text_node': {'start_chain': [HumanMessage(content='start', id='d090ab23-4242-406d-bd5b-620ceee32696')], 'transcription_response': ['hello', 'world', 'this', 'is', 'a', 'test'], 'end_chain': []}}}, 'parent_ids': []}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = compile_workflow(graph)\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "verbose = True\n",
    "dict_inputs = {\"start_chain\": \"start\"}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "async for event in workflow.astream_events(dict_inputs, version=\"v1\"):\n",
    "    if verbose:\n",
    "        print(colored(event,\"magenta\"))\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
